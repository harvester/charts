# Default values for harvester-lvm-csi-driver.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

pluginImage:
  repository: rancher/harvester-lvm-csi-plugin
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "main-head"

provisionerImage:
  repository: rancher/harvester-lvm-provisioner
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "main-head"

lvm:
  # You will want to change this for read-only filesystems
  # For example, in Talos OS, set this to "/var/etc/lvm"
  hostWritePath: /etc/lvm

  driverName: lvm.driver.harvesterhci.io

rbac:
  create: true

kubernetes:
  kubeletPath: /var/lib/kubelet

storageClasses:
  linear:
    enabled: true
    additionalAnnotations: []
    # this might be used to mark one of the StorageClasses as default:
    # storageclass.kubernetes.io/is-default-class: "true"
    reclaimPolicy: Delete
  striped:
    enabled: true
    additionalAnnotations: []
    reclaimPolicy: Delete
  mirror:
    enabled: true
    additionalAnnotations: []
    reclaimPolicy: Delete

customCSISidecars:
  enabled: false

  ## uncomment and set these if enabled=true

  # attacher: k8s.gcr.io/sig-storage/csi-attacher:v3.5.0
  # livenessprobe: k8s.gcr.io/sig-storage/livenessprobe:v2.7.0
  # provisioner: k8s.gcr.io/sig-storage/csi-provisioner:v3.2.1
  # registrar: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.5.1
  # resizer: k8s.gcr.io/sig-storage/csi-resizer:v1.6.0

nodeSelector:
  # The plugin daemonset will run on all nodes if it has a toleration,
  # so it is not necessary to set a nodeSelector for it

  # plugin:
    # node-role.kubernetes.io/master: ""
    # Key name may need to be updated to 'node-role.kubernetes.io/control-plane'
    # in the future

  # The provisioner has an affinity for nodes with a plugin pod,
  # but since that's a daemonset, we allow more fine-grained node selection

  provisioner:
    # node-role.kubernetes.io/master: ""
    # Key name may need to be updated to 'node-role.kubernetes.io/control-plane'
    # in the future

tolerations:
  plugin:
  # - key: node-role.kubernetes.io/master
  #   operator: Exists
  #   effect: NoSchedule
  # - key: node-role.kubernetes.io/control-plane
  #   operator: Exists
  #   effect: NoSchedule
  provisioner:
  # - key: node-role.kubernetes.io/master
  #   operator: Exists
  #   effect: NoSchedule
  # - key: node-role.kubernetes.io/control-plane
  #   operator: Exists
  #   effect: NoSchedule
